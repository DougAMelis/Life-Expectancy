---
title: "LifeExpectancy"
author: "Douglas Melis"
date: "10/18/2020"
output: word_document
---

```{r include=FALSE}
library(tidyverse)
library(olsrr)
library(MPV)
library(car)
library(cvTools)
library(MASS)
library(Metrics)

options(scipen=999)
```

## Data Preprocessing

Not all of the data sets I used have the standardized country code, so I had to use country names to match up the records. Unfortuantely, a number of countries have multiple names or slight variations in spellings or format. Therefore, the first step was to create a function to clean the country names column in each dataset. The function I created runs through a set of name variations and replaces each one with the variation I selected for the final dataset.
```{r}
clean_country_names <- function(data){
  data[data == "Bolivia (Plurinational State of)"] <- "Bolivia"
  data[data == "Democratic People's Republic of Korea"] <- "North Korea"
  data[data == "Cote d'Ivoire"] <- "Côte d’Ivoire"
  data[data == "CÃ´te d'Ivoire"] <- "Côte d’Ivoire"
  data[data == "Czech Republic"] <- "Czechia"
  data[data == "Egypt, Arab Rep."] <- "Egypt"
  data[data == "Swaziland"] <- "Eswatini"
  data[data == "Gambia, The"] <- "Gambia"
  data[data == "Guinea Bissau"] <- "Guinea-Bissau"
  data[data == "Iran (Islamic Republic of)"] <- "Iran"
  data[data == "Iran, Islamic Rep."] <- "Iran"
  data[data == "Kyrgyz Republic"] <- "Kyrgyzstan"
  data[data == "Lao People's Democratic Republic"] <- "Laos"
  data[data == "Lao PDR"] <- "Laos"
  data[data == "Micronesia, Fed. Sts."] <- "Micronesia"
  data[data == "Republic of Korea"] <- "South Korea"
  data[data == "Korea, Rep."] <- "South Korea"
  data[data == "Republic of Moldova"] <- "Moldova"
  data[data == "Macedonia (TFYR)"] <- "North Macedonia"
  data[data == "The former Yugoslav Republic of Macedonia"] <- "North Macedonia"
  data[data == "Micronesia (Federated States of)"] <- "Micronesia"
  data[data == "Micronesia (country)"] <- "Micronesia"
  data[data == "Russian Federation"] <- "Russia"
  data[data == "St. Lucia"] <- "Saint Lucia"
  data[data == "St. Vincent and the Grenadines"] <- "Saint Vincent and the Grenadines"
  data[data == "Slovak Republic"] <- "Slovakia"
  data[data == "Sudan (until 2011)"] <- "Sudan"
  data[data == "Syrian Arab Republic"] <- "Syria"
  data[data == "Timor	Leste"] <- "Timor-Leste"
  data[data == "United Kingdom of Great Britain and Northern Ireland"] <- "United Kingdom"
  data[data == "United States of America"] <- "United States"
  data[data == "Tanzania"] <- "United Republic of Tanzania"
  data[data == "Venezuela (Bolivarian Republic of)"] <- "Venezuela"
  data[data == "Venezuela, RB"] <- "Venezuela"
  data[data == "Viet Nam"] <- "Vietnam"
  data[data == "Yemen, Rep."] <- "Yemen"
  data[data == "Brunei Darussalam"] <- "Brunei"
  data[data == "Cape Verde"] <- "Cabo Verde"
  data[data == "Congo, Rep."] <- "Congo"
  data[data == "Congo, Dem. Rep."] <- "Democratic Republic of Congo"
  data[data == "Democratic Republic of the Congo"] <- "Democratic Republic of Congo"
  data[data == "DR Congo"] <- "Democratic Republic of Congo"
  data[data == "Macedonia"] <- "North Macedonia"
  data[data == "Timor"] <- "Timor-Leste"
  data[data == "Bahamas, The"] <- "Bahamas"
  data[data == "Korea, Dem. People’s Rep."] <- "North Korea"

  return(data)
}
```

Next I read in the data for the life expectancy variable, and removed the unnecessary columns. This data frame will act as the base that I joined to the data frames for the other variables.
```{r}
life <- read.csv("data/life expectancy.csv", header = T, stringsAsFactors = F)

data <- life[,c(1,2,5)]
data <- rename(data, Country = Location,
                Year = Period,
                Life.Expectancy = First.Tooltip)
data <- clean_country_names(data)

print(head(data))
```

Both BMI and obesity are included in the same dataset; however, they were split up by sex, which scatters each record across two rows. In order to fix that, I had to spread the data. I filtered all of the male records into one table and all of the female ones into another. I renamed the columns and joined them into a single table where each record represented one year for one country, with columns for mean male BMI, mean female BMI, the prevalence of obesity in men, and prevalence of obesity in women. Then I was able to take the average of both BMI columns to create the mean BMI for the total population, and then take the average of both obesity prevalence columns to create the mean obesity prevalence for the total population. This method assumes that the countries have equal male and female populations for each year.
```{r}
bmi <- read.csv("data/bmi.csv", header = T, stringsAsFactors = F)
bmi <- bmi[,c(1,3,4,5,8)]
names(bmi)[5] = "Obesity"
names(bmi)[1] = "Country"

bmi.men <- filter(bmi, Sex == 'Men')
bmi.men <- rename(bmi.men, BMI.M = Mean.BMI,
                Obesity.M = Obesity)
bmi.men <- bmi.men[-2]

bmi.women <- filter(bmi, Sex == 'Women')
bmi.women <- rename(bmi.women, BMI.W = Mean.BMI,
                Obesity.W = Obesity)
bmi.women <- bmi.women[-2]

bmi.both <- left_join(bmi.men, bmi.women, by = c("Country", "Year"))

bmi.both[,"BMI"] <- rowMeans(bmi.both[,c('BMI.M', 'BMI.W')], na.rm=TRUE)
bmi.both[,"Obesity"] <-rowMeans(bmi.both[,c('Obesity.M', 'Obesity.W')], na.rm=TRUE)

bmi.both <- bmi.both[,c(1,2,7,8)]

bmi.both <- clean_country_names(bmi.both)
data <- left_join(data, bmi.both, by = c("Country", "Year"))
print(head(data))

```
The alcohol dataset was split into two files to be joined, the first having columns for the years 2000-2009, and the second having columns for the years 2010-2018. After being combined, they were still in the wrong format, as the columns were not different variables, just different values of the same variable: year. In order to clean that, I had to gather the columns into a new pair of variables, putting all of the years into one variable and the alcohol consumption levels into a second variable.
```{r}
alcohol.00 <- read.csv("data/alcohol 00-09.csv", header = T, skip = 1, check.names = F, stringsAsFactors = F)
alcohol.00 <- alcohol.00[,-c(2,3)]

alcohol.00 <- gather(alcohol.00, `2009`, `2008`, `2007`, `2006`, `2005`, `2004`, `2003`, `2002`, `2001`, `2000`, key = "Year", value = "Alcohol")

alcohol.10 <- read.csv("data/alcohol 10-18.csv", header = T, skip = 1, check.names = F, stringsAsFactors = F)
alcohol.10 <- alcohol.10[,-c(2,3)]

alcohol.10 <- gather(alcohol.10, `2018`, `2017`, `2016`, `2015`, `2014`, `2013`, `2012`, `2011`, `2010`, key = "Year", value = "Alcohol")

alcohol <- rbind(alcohol.00, alcohol.10)

alcohol[,"Year"] <- as.numeric(alcohol[,"Year"])

alcohol <- clean_country_names(alcohol)
data <- left_join(data, alcohol, by = c("Country", "Year"))
print(head(data))
```

The GDP dataset had the same structure as the alcohol consumption, so I used the same gather process, creating a year variable and a GDP variable.
```{r}
gdp <- read.csv("data/GDP per capita.csv", header = T, check.names = F, stringsAsFactors = F)
gdp <- gdp[,c('Country Name', '2018', '2017', '2016', '2015', '2014', '2013', '2012', '2011', '2010',
              '2009', '2008', '2007', '2006', '2005', '2004', '2003', '2002', '2001', '2000')]

gdp <- gather(gdp, `2018`, `2017`, `2016`, `2015`, `2014`, `2013`, `2012`, `2011`, `2010`, `2009`,
              `2008`, `2007`, `2006`, `2005`, `2004`, `2003`, `2002`, `2001`, `2000`, key = "Year", value = "GDP")

gdp[,"Year"] <- as.numeric(gdp[,"Year"])
names(gdp)[1] <- "Country"

gdp <- clean_country_names(gdp)
data <- left_join(data, gdp, by = c("Country", "Year"))
print(head(data))
```
The HIV/AIDS dataset was already in the required format, so I only had to remove the unnecessary columns.
```{r}
hiv <- read.csv("data/deaths-and-new-cases-of-hiv.csv", header = T, stringsAsFactors = F)
hiv <- hiv[,c(1,3,5,6)]
names(hiv) <- c("Country", "Year", "HIV.Prevalence", "HIV.Incidence")

hiv <- clean_country_names(hiv)
data <- left_join(data, hiv, by = c("Country", "Year"))
print(head(data))
```

The diabetes dataset had the same structure as the BMI and obesity dataset, so I used the same process to restructure the age-standardized diabetes prevalence data.
```{r}
diabetes <- read.csv("data/diabetes.csv", header = T, stringsAsFactors = F)
diabetes <- diabetes[,c(1,3,4,5)]
names(diabetes)[4] = "Diabetes"
names(diabetes)[1] = "Country"

diabetes.men <- filter(diabetes, Sex == 'Men')
diabetes.men <- rename(diabetes.men, Diabetes.M = Diabetes)
diabetes.men <- diabetes.men[-2]

diabetes.women <- filter(diabetes, Sex == 'Women')
diabetes.women <- rename(diabetes.women, Diabetes.W = Diabetes)
diabetes.women <- diabetes.women[-2]

diabetes.both <- left_join(diabetes.men, diabetes.women, by = c("Country", "Year"))

diabetes.both[,"Diabetes"] <- rowMeans(diabetes.both[,c('Diabetes.M', 'Diabetes.W')], na.rm=TRUE)

diabetes.both <- diabetes.both[,c(1,2,5)]

diabetes.both <- clean_country_names(diabetes.both)
data <- left_join(data, diabetes.both, by = c("Country", "Year"))
print(head(data))
```

For the immunizations, I anticipated that using all ten of them would result in serious multicollinearity problems, so I decided to compute an average immunization coverage value for all ten immunizations. In order to do so, I joined the datasets for each vaccine into one immunization table. Then I created a new column that was the mean of the values in all the other columns.
```{r}
bcg <- read.csv("data/bcg.csv", header = T, stringsAsFactors = F)
bcg <- bcg[,c(1,3,4)]
names(bcg) <- c("Country", "Year", "BCG")

bcg <- subset(bcg, Year >= 2000)

immunization <- bcg


add_vaccine <- function(immunization, file.name, vaccine.name){
  vaccine <- read.csv(file.name, header = T, stringsAsFactors = F)
  vaccine <- vaccine[,c(1,3,4)]
  names(vaccine) <- c("Country", "Year", vaccine.name)
  
  vaccine <- subset(vaccine, Year >= 2000)

  immunization <- full_join(immunization, vaccine, by = c("Country", "Year"))
  return(immunization)
}

immunization <- add_vaccine(immunization, "data/dtp3.csv", "DTP3")
immunization <- add_vaccine(immunization, "data/hepb3.csv", "HepB3")
immunization <- add_vaccine(immunization, "data/hib3.csv", "Hib3")
immunization <- add_vaccine(immunization, "data/mcv1.csv", "MCV1")
immunization <- add_vaccine(immunization, "data/mcv2.csv", "MCV2")
immunization <- add_vaccine(immunization, "data/pab.csv", "PAB")
immunization <- add_vaccine(immunization, "data/pcv3.csv", "PCV3")
immunization <- add_vaccine(immunization, "data/pol3.csv", "Pol3")
immunization <- add_vaccine(immunization, "data/rotac.csv", "RotaC")

print(head(immunization))

immunization.avg <- immunization
immunization.avg[,"Immunization"] <- rowMeans(immunization.avg[,c('BCG', 'DTP3', 'HepB3', 'Hib3','Pol3', 'MCV1',
                                                 'MCV2', 'PAB', 'PCV3', 'RotaC')], na.rm=TRUE)

immunization.avg <- immunization.avg[,c("Country", "Year", "Immunization")]

data <- left_join(data, immunization.avg, by = c("Country", "Year"))
print(head(data))
```

Since linear regression cannot handle missing values, I removed all records with at least one missing value. Next I used min/max normalization on the data since the scales are different for most of the variables.
```{r}
data <- data[,c("Life.Expectancy", "BMI", "Obesity", "Alcohol", "GDP", "HIV.Prevalence", "HIV.Incidence", 
                              "Diabetes", "Immunization")]


data <- data[complete.cases(data),]

normalize <- function(x){
    return((x- min(x)) /(max(x)-min(x)))
}

data.norm <- lapply(data, normalize)

data.norm <- as.data.frame(data.norm)
```

## Exploring the Data

I created scatterplots with life expectancy on the left axis for each of my regressors. I also created a scatterplot matrix of all variables to examine how each variable interacted with each of the others.
```{r}
for(i in 2:ncol(data.norm)){
  scatterplot(y=data.norm[,"Life.Expectancy"], x=data.norm[,i])
}

pairs(data.norm, lower.panel = NULL)
```

I noticed that the fourth graph (life expectancy versus GDP) had a sharp bend, indicating that the relationship could be exponential.
I created a new variable to be the natural log of the original, non-normalized GDP variable. I then normalized this new natural log of GDP variable. I then made a scatterplot with life expectancy on the y-axis and the natural log of GDP on the x-axis and compared it to the original. The graph of life expectancy versus natural log of GDP did not have the bend in it and closely resembled a strong linear relationship. Therefore, I used the natual log of GDP for the regression.
```{r}
data.norm[,"GDP.ln"] <- as.data.frame(normalize(log(data[,"GDP"])))

scatterplot(y=data.norm[,"Life.Expectancy"], x=data.norm[,"GDP"])
scatterplot(y=data.norm[,"Life.Expectancy"], x=data.norm[,"GDP.ln"])

```

I noticed that the seventh graph (life expectancy versus diabetes) had a bend, similar to the bend in GDP. I carried out the same process on the diabetes variable to create the natural log of Diabetes. The graph of life expectancy versus natural log of diabetes appears to be more linear than that of the original. Therefore, I used the natural log of diabetes for the regression. 
```{r}
data.norm[,"Diabetes.ln"] <- as.data.frame(normalize(log(data[,"Diabetes"])))

scatterplot(y=data.norm[,"Life.Expectancy"], x=data.norm[,"Diabetes"])
scatterplot(y=data.norm[,"Life.Expectancy"], x=data.norm[,"Diabetes.ln"])

```

I noticed that the first graph (life expectancy versus BMI) was curved and that the highest values were in the middle, indicating that the relationship may not be linear.
I took the median value of the healthy BMI range, 21.7, and subtracted it from the original, non-normalized BMI column, took the absolute value, and normalized it. I then created a scatterplot with life expectancy on the y-axis and the new absolute value BMI on the x-axis and compared it to the original. The graph of life expectancy versus absolute value BMI appeared only slightly more linear than the original BMI graph, if anything. Therefore, I did not use the absolute value of BMI for the regression.
```{r}
data.norm[,"BMI.abs"] <- as.data.frame(normalize(abs(data[,"BMI"] - 21.7)))

scatterplot(y=data.norm[,"Life.Expectancy"], x=data.norm[,"BMI"])
scatterplot(y=data.norm[,"Life.Expectancy"], x=data.norm[,"BMI.abs"])

data.norm <- subset(data.norm, select = -BMI.abs)
```

I randomly split the data into a test set and a train set.
```{r}
set.seed(43)
data.split = sort(sample(nrow(data.norm), nrow(data.norm)*.8))

data.train = data.norm[data.split,]
data.test = data.norm[-data.split,]
```

## Finding the Best Predictors

For each of the models, I calculated the PRESS statistic, and variance inflation factors for the model. Then I tested for normality. I created a function to perform these tests.
```{r}
model_info <- function(model){
  print(summary(model))

  print(paste("PRESS:", PRESS(model), sep=' '))
}

```

I created a model named baseline with all of the original regressors. This baseline does not include the modified regressors, such as natural log of GDP. This baseline will be used to compare to the models with the best predictors.
```{r}
baseline <- lm(Life.Expectancy ~ GDP + Immunization + HIV.Prevalence + BMI + HIV.Incidence + Diabetes + Alcohol + Obesity, data.train)
model_info(baseline)
```


For Model 1, I used all regressors, but used natural log of GDP instead of the original GDP variable.
```{r}
model.1 <- lm(Life.Expectancy ~ GDP.ln + Immunization + HIV.Prevalence + BMI + HIV.Incidence + Diabetes + Alcohol + Obesity, data.train)
model_info(model.1)
```

For Model 2, I used all regressors, but used natural log of diabetes instead of the original diabetes variable.
```{r}
model.2 <- lm(Life.Expectancy ~ GDP + Immunization + HIV.Prevalence + BMI + HIV.Incidence + Diabetes.ln + Alcohol + Obesity, data.train)
model_info(model.2)
```

For Model 2, I used all regressors, but used both natural log of diabetes and natural log of GDP instead of the original diabetes and GDP variables.
```{r}
model.3 <- lm(Life.Expectancy ~ GDP.ln + Immunization + HIV.Prevalence + BMI + HIV.Incidence + Diabetes.ln + Alcohol + Obesity, data.train)
model_info(model.3)
```

I made Models 4-7 to replicate the above, but used stepwise selection to eliminate unnecessary regressors.
Model 4 is similar to the baseline, but obesity and HIV incidence were not used.
```{r}
stepwise.4 <- ols_step_forward_p(baseline, pent=.04)
stepwise.4
plot(stepwise.4, which=1)
model.4 <- stepwise.4$model
model_info(model.4)
```

Model 5 is similar to Model 1, but obesity and HIV incidence were not used.
```{r}
stepwise.5 <- ols_step_forward_p(model.1, pent=.04)
stepwise.5
plot(stepwise.5, which=1)
model.5 <- stepwise.5$model
model_info(model.5)
```

Model 6 is similar to Model 2, but obesity and HIV incidence are not used.
```{r}
stepwise.6 <- ols_step_forward_p(model.2, pent=.04)
stepwise.6
plot(stepwise.6, which=1)
model.6 <- stepwise.6$model
model_info(model.6)
```

Model 7 is similar to Model 3, but alcohol, obesity, and natural log of diabetes are unused.
```{r}
stepwise.7 <- ols_step_forward_p(model.3, pent=.04)
stepwise.7
plot(stepwise.7, which=1)
model.7 <- stepwise.7$model
model_info(model.7)
```

## Selecting the Best Model

I performed cross validation on my models, and compared the results.
```{r}
folds <- cvFolds(nrow(data.train), K = 10, R =100)
cvfit0 <- cvLm(baseline, cost = rtmspe, folds = folds)
cvfit1 <- cvLm(model.1, cost = rtmspe, folds = folds)
cvfit2 <- cvLm(model.2, cost = rtmspe, folds = folds)
cvfit3 <- cvLm(model.3, cost = rtmspe, folds = folds)
cvfit4 <- cvLm(lm(model.4$terms, data.train), cost = rtmspe, folds = folds)
cvfit5 <- cvLm(lm(model.5$terms, data.train), cost = rtmspe, folds = folds)
cvfit6 <- cvLm(lm(model.6$terms, data.train), cost = rtmspe, folds = folds)
cvfit7 <- cvLm(lm(model.7$terms, data.train), cost = rtmspe, folds = folds)
cvFits <- cvSelect(Baseline = cvfit0, Model1 = cvfit1, Model2 = cvfit2, Model3 = cvfit3, Model4 = cvfit4,
                   Model5 = cvfit5, Model6 = cvfit6, Model7 = cvfit7)
cvFits
```

Model 5 performed best in the cross validation, therefore it is the final model I selected. I then ran the test data through Model 5, and recorded several performance metrics.
```{r}
test.labels <- data.test[,1]
test <- data.test[,-1]
pred <- predict(model.5, test)

mae <- mae(test.labels, pred)
print(paste("MAE", mae, sep=' '))
mse <- mse(test.labels, pred)
print(paste("MSE", mse, sep=' '))
rmse <- rmse(test.labels, pred)
print(paste("RMSE", rmse, sep=' '))
mape <- mape(test.labels, pred)
print(paste("MAPE", mape, sep=' '))
smape <- smape(test.labels, pred)*100
print(paste("SMAPE", smape, sep=' '))

rsq <- function(x, y){
  return(cor(x, y) ^ 2)
}

rsq <- rsq(test.labels, pred)
print(paste("RSQ", rsq, sep=' '))

model_info(model.5)
plot(model.5)
print("VIF:")
print(vif(model.5))
ols_test_normality(model.5)

```

## Results

In the final model, every regressor estimate has a p-value < .05, indicating that they are all significant at the 95% confidence level.
The model had a symmetric mean absolute percentage error on the test data of 13.11, indicating that on average, the model is off by 13.11% on data it has never seen. The model achieved an R2 of .7453, indicating the model accounts for about 74.53% of the data variation.

The variance inflation factors for Model 5, are all below 5, indicating that there is no serious multicollinearity in the model.

The Normal Q-Q plot for the model is very close to normal on the right side but deviates significantly on the left end. The residuals versus fitted plot indicates that the residuals do not have constant variance. The left side of the plot is more skewed towards positive residuals, the middle is more skewed towards negative residuals, and the right side has less variation. These plots indicate that while the model performs pretty well, it is not exactly adequate. Further, I performed four different tests for normality, Shapiro-Wilk, Kolmogorov-Smirnov, Cramer-von Mises, and Anderson-Darling. The p-values for all four tests were 0; therefore, we reject the null hypothesis that the data is normal. This rejection further indicates that the model is not exactly adequate for the data, even though it performs pretty well.
